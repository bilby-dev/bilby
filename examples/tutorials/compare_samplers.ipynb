{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare samplers\n",
    "\n",
    "In this notebook, we'll compare the different samplers implemented in `Bilby` on a simple linear regression problem.\n",
    "\n",
    "This is not an exhaustive set of the implemented samplers, nor of the settings available for each sampler.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bilby\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bilby.core.utils.random import seed, rng\n",
    "\n",
    "# Sets seed of bilby's generator \"rng\" to \"123\" to ensure reproducibility\n",
    "seed(123)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"linear_regression\"\n",
    "outdir = \"outdir\"\n",
    "bilby.utils.check_directory_exists_and_if_not_mkdir(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our model\n",
    "\n",
    "Here our model is a simple linear fit to some quantity $y = m x + c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, m, c):\n",
    "    return x * m + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate data\n",
    "\n",
    "We simulate observational data.\n",
    "We assume some uncertainty in the observations and so perturb the observations from the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injection_parameters = dict(m=0.5, c=0.2)\n",
    "\n",
    "sampling_frequency = 10\n",
    "time_duration = 10\n",
    "time = np.arange(0, time_duration, 1 / sampling_frequency)\n",
    "N = len(time)\n",
    "sigma = rng.normal(1, 0.01, N)\n",
    "data = model(time, **injection_parameters) + rng.normal(0, sigma, N)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(time, data, \"x\", label=\"Data\")\n",
    "ax.plot(time, model(time, **injection_parameters), \"--r\", label=\"Truth\")\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(-2, 8)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the likelihood and prior\n",
    "\n",
    "For any Bayesian calculation we need a likelihood and a prior.\n",
    "\n",
    "In this case, we take a `GausianLikelihood` as we assume the uncertainty on the data is normally distributed.\n",
    "\n",
    "For both of our parameters we take uniform priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = bilby.likelihood.GaussianLikelihood(time, data, model, sigma)\n",
    "\n",
    "priors = bilby.core.prior.PriorDict()\n",
    "priors[\"m\"] = bilby.core.prior.Uniform(0, 5, \"m\")\n",
    "priors[\"c\"] = bilby.core.prior.Uniform(-2, 2, \"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the samplers and compare the inferred posteriors\n",
    "\n",
    "We'll use four of the implemented samplers.\n",
    "\n",
    "For each one we specify a set of parameters.\n",
    "\n",
    "`Bilby`/the underlying samplers produce quite a lot of output while the samplers are running so we will suppress as many of these as possible.\n",
    "\n",
    "After running the analysis, we print a final summary for each of the samplers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = dict(\n",
    "    bilby_mcmc=dict(\n",
    "        nsamples=1000,\n",
    "        L1steps=20,\n",
    "        ntemps=10,\n",
    "        printdt=10,\n",
    "    ),\n",
    "    dynesty=dict(npoints=500, sample=\"acceptance-walk\", naccept=20),\n",
    "    pymultinest=dict(nlive=500),\n",
    "    nestle=dict(nlive=500),\n",
    "    emcee=dict(nwalkers=20, iterations=500),\n",
    "    ptemcee=dict(ntemps=10, nwalkers=20, nsamples=1000),\n",
    ")\n",
    "\n",
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilby.core.utils.logger.setLevel(\"ERROR\")\n",
    "\n",
    "for sampler in samplers:\n",
    "    result = bilby.core.sampler.run_sampler(\n",
    "        likelihood,\n",
    "        priors=priors,\n",
    "        sampler=sampler,\n",
    "        label=sampler,\n",
    "        resume=False,\n",
    "        clean=True,\n",
    "        verbose=False,\n",
    "        **samplers[sampler]\n",
    "    )\n",
    "    results[sampler] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 40)\n",
    "for sampler in results:\n",
    "    print(sampler)\n",
    "    print(\"=\" * 40)\n",
    "    print(results[sampler])\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make comparison plots\n",
    "\n",
    "We will make two standard comparison plots.\n",
    "\n",
    "In the first we plot the one- and two-dimensional marginal posterior distributions in a \"corner\" plot.\n",
    "\n",
    "In the second, we show the inferred model that we are fitting along with the uncertainty by taking random draws from the posterior distribution.\n",
    "This kind of posterior predicitive plot is useful to identify model misspecification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = bilby.core.result.plot_multiple(\n",
    "    list(results.values()), labels=list(results.keys()), save=False\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(time, data, \"x\", label=\"Data\", color=\"r\")\n",
    "ax.plot(\n",
    "    time, model(time, **injection_parameters), linestyle=\"--\", color=\"k\", label=\"Truth\"\n",
    ")\n",
    "\n",
    "for jj, sampler in enumerate(samplers):\n",
    "    result = results[sampler]\n",
    "    samples = result.posterior[result.search_parameter_keys].sample(500)\n",
    "    for ii in range(len(samples)):\n",
    "        parameters = dict(samples.iloc[ii])\n",
    "        plt.plot(time, model(time, **parameters), color=f\"C{jj}\", alpha=0.01)\n",
    "    plt.axhline(-10, color=f\"C{jj}\", label=sampler.replace(\"_\", \" \"))\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(-2, 8)\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
